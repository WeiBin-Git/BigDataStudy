#### MapReduce
* 为什么要分两部分： Map进行分，Reduce负责合，为了实现分布式计算，提高计算效率。
* MapReduce是什么：hadoop核心组件之一，分布式计算框架，用于编写批处理应用程序，编写好的程序可以提交到hadoop集群上用于并行处理大规模数据集，通常将输入数据集拆分成数据块，map任务并行处理，框架对map输出进行排序后输出到reduce里，输入和输出存储在文件系统，安排任务，监视任务并重新执行失败的任务；map是映射的过程，recude任务是归纳的过程；
* shuffle过程（还不会）：
  * 在map端和reduce端都有
  * 四个步骤：分区，排序，combiner，分组
  * map之后，将数据标记好分区发送到环形缓冲区（默认大小100MB，达到80%进行溢写），溢写前对数据进行排序（字典序排序，快排），溢写达到10个进行merge(归并), combiner-局部聚合，
* MapReduce优化
  * 每个文件都在namenode记录元数据信息，文件很小的话会产生很多文件；会造成namenode压力；增加磁盘寻址次数，
  * 小文件优化：1、从源头，上传时合并归档生成HAR；2、读取时实现combinerinputformat会合并；
  * 数据倾斜优化：1、自定义分区，修改分区逻辑；2、加盐；3、加reduce内存；4、增加reduce个数；5、推测执行；6：JVM重用
  * JVM重用：每个task都需要开jvm初始化，开启jvm比较耗时；
* Map端优化：调参，让Map执行效率最高，减少环形缓冲区flush次数；对Map输出的数据进行压缩，但是会消耗内存；
* reduce端优化：调大内存，在内存中进行计算；减少环形缓冲区flush次数；
* 集群调优核心思路：在网络带宽，磁盘IO是瓶颈的前提下，能不使用IO和网络就不使用；
* 实现两表join：
  * mapjoin：一个表大一个表小，把小表放到内存；每个maptask放一个小表；可以实现不等值连接；
  * ReduceJoin：map阶段仅对key进行hash，并标记数据来自于哪个表；shuffle阶段进行数据合并，reduce阶段进行数据乘积；由于没有对数据进行瘦身，网络和排序性能很低，而且reduce对2个集合乘积，很耗内存；容易oom；
* 排序发生在哪几个阶段：
  * map 和reduce 都有排序，快排和归并
  * map阶段：本次磁盘按照key排序，快排，合并用归并排序
  * Recude阶段：每个recude会对收到的数据进行排序，按照key分成若干组，归并排序
  * 避免排序：不使用reduce
* 序列化和反序列化
  * 把结构化对象转换成字节流--序列化
  * 进程间传递对象，写磁盘需要序列化
  * hadoop自己开发机制
  * 简洁，精简，高效，不用想java传输多层父子关系，需要哪个属性就用哪个属性  Verytable
* combiner(可选)
  * MR程序中map和Reduce之外的组件
  * 在每个maptask所在节点运行
  * 对每一个maptask的输出进行汇总，用于减少网络传输
  * 进行一次localreduce
  * 自定义一个combiner类继承reducer重写reduce方法，在job中设置set.combinerclass方法实现此功能
  * 应用前提，不能影响最终业务逻辑
* 每一个maptask都存储着一个环形缓冲区，存储着map输出的结